{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucene\n",
    "from org.apache.lucene.document import Document, Field\n",
    "from org.apache.lucene.search import IndexSearcher, Explanation\n",
    "from org.apache.lucene.search.similarities import TFIDFSimilarity, LMJelinekMercerSimilarity;\n",
    "from org.apache.lucene.index import IndexReader,DirectoryReader,TermsEnum,Term\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.store import SimpleFSDirectory, FSDirectory\n",
    "from org.apache.lucene.util import Version, BytesRefIterator\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.analysis.core import WhitespaceAnalyzer \n",
    "from org.apache.lucene.queryparser.flexible.standard import StandardQueryParser\n",
    "from sklearn.utils import check_random_state\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from java.io import File\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "import lime\n",
    "from lime import lime_ranker\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the samples\n",
    "index_path = '/Users/manishav/workspace/irexplain/trec_index'\n",
    "samples_path = '/Users/manishav/workspace/irexplain/samples/pointwise/samples_tfidf.txt'\n",
    "\n",
    "\n",
    "\n",
    "def load_samples(file_path):\n",
    "    samples_list = {}\n",
    "    with open(file_path, 'r') as ifile:\n",
    "        for line in ifile:\n",
    "            split = line.split('\\t')\n",
    "            doc_id = split[1][:split[1].rindex('_')]\n",
    "            if doc_id not in samples_list:\n",
    "                samples_list[doc_id] = []\n",
    "            try:\n",
    "                samples_list[doc_id].append({'query_id':split[0], 'sample_id':split[1], 'sample_text': split[3].strip(),\\\n",
    "                                         'sample_score': float(split[4])})\n",
    "            except:\n",
    "                print(split)\n",
    "    return samples_list\n",
    "\n",
    "#[\\\\\\\\/:*?\"<>|]\n",
    "\n",
    "def tokenize_text(text):\n",
    "    analyzer = EnglishAnalyzer()\n",
    "    parser = StandardQueryParser(analyzer)\n",
    "    parsed_text = parser.parse(text,'').toString('')\n",
    "    parsed_text = re.sub('[)()]', '', parsed_text)\n",
    "    return parsed_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker_explanation = lime_ranker.LimeRankerExplainer(1, None, True, [0,1,2,3,4], index_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['449 ', 'FBIS4-23025_172', '', 'spokesman']\n"
     ]
    }
   ],
   "source": [
    "samples = load_samples(samples_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0091', '1', '10', '130', '182123', '1990', '27', '30', '77', 'accid', 'ad', 'american', 'author', 'bu', 'carri', 'center', 'citi', 'column', 'desk', 'determin', 'diplomat', 'edit', 'embank', 'februari', 'foot', 'foreign', 'germani', 'home', 'hurt', 'immedi', 'injur', 'injuri', 'la022790', 'leav', 'militari', 'minor', 'oberwesel', 'page', 'part', 'passeng', 'personnel', 'plung', 'polic', 'recreat', 'rel', 'report', 'rhine', 'river', 'road', 'spokesman', 'staff', 'suffer', 'time', 'tour', 'tourism', 'tourist', 'tuesdai', 'twenti', 'u.', 'west', 'wire', 'word', 'world', 'youth'])\n",
      "'2790' is not in list  :: Sample 2790 0091 youth passeng staff diplomat center 182123 77 77 182123 wire suffer\n",
      "'uari' is not in list  :: Sample west 77 77 recreat 30 recreat author uari river foot recreat desk\n",
      "'2790' is not in list  :: Sample accid injur passeng ad minor la022790 0091 oberwesel 2790 0091 germani recreat recreat part\n",
      "'2790' is not in list  :: Sample home 2790 0091 0091 1990 la022790 0091 30 time 182123 injur 0091 citi la022790 0091\n",
      "'uari' is not in list  :: Sample 182123 part uari tuesdai oberwesel injur la022790 0091 1 77 immedi immedi 182123\n",
      "'2790' is not in list  :: Sample wire bu american 0091 oberwesel page tuesdai la022790 0091 injur column 2790 0091 column\n",
      "'uari' is not in list  :: Sample rel american uari accid plung 130 foot 2790 0091 author desk recreat 77 youth\n",
      "'2790' is not in list  :: Sample rel american uari accid plung 130 foot 2790 0091 author desk recreat 77 youth\n",
      "'2790' is not in list  :: Sample desk 182123 2790 0091 rhine river determin youth foreign diplomat american plung determin\n",
      "'uari' is not in list  :: Sample column suffer uari twenti twenti personnel 182123 oberwesel militari plung ad tour\n",
      "'2790' is not in list  :: Sample river 0091 diplomat oberwesel wire edit personnel river diplomat road 2790 0091 tourist\n",
      "'2790' is not in list  :: Sample tourist oberwesel 77 hurt bu 77 spokesman word american plung 2790 0091 west\n",
      "'2790' is not in list  :: Sample immedi 2790 0091 130 foot 182123 carri suffer tourism recreat la022790 0091 river ad twenti\n",
      "(51,) (50, 1) (51, 64)\n",
      "Data and label shape (51, 64) (50,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [51, 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2d5fa577a558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msample_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msample_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mexplain_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranker_explanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_document_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/lime-0.1.1.32-py3.7.egg/lime/lime_ranker.py\u001b[0m in \u001b[0;36mexplain_document_label\u001b[0;34m(self, document_id, samples, samples_scores, num_features)\u001b[0m\n\u001b[1;32m    256\u001b[0m                  \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mmodel_regressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 feature_selection=self.feature_selection)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/lime-0.1.1.32-py3.7.egg/lime/lime_base.py\u001b[0m in \u001b[0;36mexplain_instance_with_data\u001b[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[1;32m    156\u001b[0m                                                \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                                                \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                                                feature_selection)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_regressor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/lime-0.1.1.32-py3.7.egg/lime/lime_base.py\u001b[0m in \u001b[0;36mfeature_selection\u001b[0;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mn_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'highest_weights'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             return self.feature_selection(data, labels, weights,\n\u001b[0;32m--> 107\u001b[0;31m                                           num_features, n_method)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     def explain_instance_with_data(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/lime-0.1.1.32-py3.7.egg/lime/lime_base.py\u001b[0m in \u001b[0;36mfeature_selection\u001b[0;34m(self, data, labels, weights, num_features, method)\u001b[0m\n\u001b[1;32m     79\u001b[0m                         random_state=self.random_state)\n\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data and label shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             feature_weights = sorted(zip(range(data.shape[0]),\n\u001b[1;32m     83\u001b[0m                                          clf.coef_ * data[0]),\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scikit_learn-0.20.2-py3.7-macosx-10.9-x86_64.egg/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scikit_learn-0.20.2-py3.7-macosx-10.9-x86_64.egg/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         X, y = check_X_y(X, y, ['csr', 'csc', 'coo'], dtype=_dtype,\n\u001b[0;32m--> 491\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scikit_learn-0.20.2-py3.7-macosx-10.9-x86_64.egg/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scikit_learn-0.20.2-py3.7-macosx-10.9-x86_64.egg/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [51, 50]"
     ]
    }
   ],
   "source": [
    "for doc_id, sample_list in samples.items():\n",
    "    sample_scores = [x['sample_score'] for x in sample_list]\n",
    "    sample_texts = [tokenize_text(x['sample_text']) for x in sample_list]\n",
    "    explain_object = ranker_explanation.explain_document_label(doc_id, sample_texts, sample_scores, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['LA022790-0091'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucene.initVM(classpath=lucene.CLASSPATH, vmargs=['-Djava.awt.headless=true'])\n",
    "analyzer = StandardAnalyzer()\n",
    "print(lucene.CLASSPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text('2790-0091 youths passengers staff diplomatic center 182123 77 77 182123 wire suffered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexPath = File(index_path).toPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dir = FSDirectory.open(indexPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = DirectoryReader.open(index_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = IndexSearcher(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = 'words'\n",
    "analyzer = WhitespaceAnalyzer()\n",
    "query_parser = QueryParser('id', analyzer)\n",
    "score_docs = searcher.search(query_parser.parse(str('LA022790-0091')),1).scoreDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "tc_dict = {}                     # Counts of each term\n",
    "dc_dict = {}                     # Number of docs associated with each term\n",
    "tfidf_dict = {}   \n",
    "if len(score_docs) > 0:\n",
    "    # get the tf-idf vector.\n",
    "    termVector = reader.getTermVector(score_docs[0].doc, text_field);\n",
    "    termsEnumvar = termVector.iterator()\n",
    "    termsref = BytesRefIterator.cast_(termsEnumvar)\n",
    "    N_terms = 0\n",
    "    try:\n",
    "        while (termsref.next()):\n",
    "            termval = TermsEnum.cast_(termsref)\n",
    "            fg = termval.term().utf8ToString()       # Term in unicode\n",
    "            tc = termval.totalTermFreq()             # Term count in the doc\n",
    "\n",
    "            # Number of docs having this term in the index\n",
    "            dc = reader.docFreq(Term(text_field, termval.term())) \n",
    "            N_terms = N_terms + 1 \n",
    "            tc_dict[fg]=tc\n",
    "            dc_dict[fg]=dc\n",
    "    except:\n",
    "        print('error in term_dict')\n",
    "\n",
    "    # Compute TF-IDF for each term\n",
    "    for term in tc_dict:\n",
    "        tf = tc_dict[term] / N_terms\n",
    "        idf = 1 + math.log(reader.numDocs()/(dc_dict[term]+1)) \n",
    "        tfidf_dict[term] = tf*idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

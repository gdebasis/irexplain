{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=/home/manishav/addons/site-packages/:/home/manishav/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matchzoo as mz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetch the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://msmarco.blob.core.windows.net/msmarcoranking/qrels.train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load the embeddings\n",
    "#!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import matchzoo as mz\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "print(mz.__version__)\n",
    "from scipy.spatial.distance import cosine\n",
    "from matchzoo.metrics import Precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Precision for ranking.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from matchzoo.engine.base_metric import BaseMetric, sort_and_couple\n",
    "\n",
    "\n",
    "### Add \n",
    "\n",
    "class PrecisionCheck(BaseMetric):\n",
    "    \"\"\"Precision metric.\"\"\"\n",
    "\n",
    "    ALIAS = 'precision'\n",
    "\n",
    "    def __init__(self, k: int = 1, threshold: float = 0.):\n",
    "        \"\"\"\n",
    "        :class:`PrecisionMetric` constructor.\n",
    "        :param k: Number of results to consider.\n",
    "        :param threshold: the label threshold of relevance degree.\n",
    "        \"\"\"\n",
    "        self._k = k\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\":return: Formated string representation of the metric.\"\"\"\n",
    "        return f\"{self.ALIAS}@{self._k}({self._threshold})\"\n",
    "\n",
    "    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n",
    "        #print('number of results', y_true.shape)\n",
    "        \"\"\"\n",
    "        Calculate precision@k.\n",
    "        Example:\n",
    "            >>> y_true = [0, 0, 0, 1]\n",
    "            >>> y_pred = [0.2, 0.4, 0.3, 0.1]\n",
    "            >>> Precision(k=1)(y_true, y_pred)\n",
    "            0.0\n",
    "            >>> Precision(k=2)(y_true, y_pred)\n",
    "            0.0\n",
    "            >>> Precision(k=4)(y_true, y_pred)\n",
    "            0.25\n",
    "            >>> Precision(k=5)(y_true, y_pred)\n",
    "            0.2\n",
    "        :param y_true: The ground true label of each document.\n",
    "        :param y_pred: The predicted scores of each document.\n",
    "        :return: Precision @ k\n",
    "        :raises: ValueError: len(r) must be >= k.\n",
    "        \"\"\"\n",
    "        if self._k <= 0:\n",
    "            raise ValueError(f\"k must be greater than 0.\"\n",
    "                             f\"{self._k} received.\")\n",
    "        # sorted list of pairs.\n",
    "        coupled_pair = sort_and_couple(y_true, y_pred)\n",
    "        \n",
    "        precision = 0.0\n",
    "        \n",
    "        for idx, (label, score) in enumerate(coupled_pair):\n",
    "            \n",
    "            #if idx < 10:\n",
    "            #    print('[',label, score, ']', )\n",
    "            if idx >= self._k:\n",
    "                break\n",
    "            if label > self._threshold:\n",
    "                precision += 1.\n",
    "        return precision / self._k\n",
    "    \n",
    "    \n",
    "\"\"\"Recall for ranking.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from matchzoo.engine.base_metric import BaseMetric, sort_and_couple\n",
    "\n",
    "\n",
    "class RecallCheck(BaseMetric):\n",
    "    \"\"\"Recall metric.\"\"\"\n",
    "\n",
    "    ALIAS = 'recall'\n",
    "\n",
    "    def __init__(self, k: int = 1, threshold: float = 0.):\n",
    "        \"\"\"\n",
    "        :class:`RecallMetric` constructor.\n",
    "        :param k: Number of results to consider.\n",
    "        :param threshold: the label threshold of relevance degree.\n",
    "        \"\"\"\n",
    "        self._k = k\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\":return: Formated string representation of the metric.\"\"\"\n",
    "        return f\"{self.ALIAS}@{self._k}({self._threshold})\"\n",
    "\n",
    "    def __call__(self, y_true: np.array, y_pred: np.array) -> float:\n",
    "        if self._k == 5:\n",
    "            print('number of results', y_true.shape, (y_true > self._threshold ).sum())\n",
    "        \"\"\"\n",
    "        Calculate Recall@k.\n",
    "        Example:\n",
    "            >>> y_true = [0, 0, 0, 1]\n",
    "            >>> y_pred = [0.2, 0.4, 0.3, 0.1]\n",
    "            >>> Recall(k=1)(y_true, y_pred)\n",
    "            0.0\n",
    "            >>> Recall(k=2)(y_true, y_pred)\n",
    "            0.0\n",
    "            >>> Recall(k=4)(y_true, y_pred)\n",
    "            1.0\n",
    "            >>> Recall(k=5)(y_true, y_pred)\n",
    "            1.0\n",
    "        :param y_true: The ground true label of each document.\n",
    "        :param y_pred: The predicted scores of each document.\n",
    "        :return: Recall @ k\n",
    "        :raises: ValueError: len(r) must be >= k.\n",
    "        \"\"\"\n",
    "        if self._k <= 0:\n",
    "            raise ValueError(f\"k must be greater than 0.\"\n",
    "                             f\"{self._k} received.\")\n",
    "        # sorted list of pairs.\n",
    "        coupled_pair = sort_and_couple(y_true, y_pred)\n",
    "        \n",
    "        recall = 0.0\n",
    "        rel_docs = (y_true > self._threshold ).sum() * 1.0\n",
    "        for idx, (label, score) in enumerate(coupled_pair):\n",
    "            \n",
    "            if idx < 5 and self._k == 5:\n",
    "                print('[',label, score, ']', )\n",
    "            if idx >= self._k:\n",
    "                break\n",
    "            if label > self._threshold:\n",
    "                recall += 1.\n",
    "        return recall / rel_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Matchzoo toolkit for token embedding.\"\"\"\n",
    "\n",
    "import csv\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Embedding(object):\n",
    "    \"\"\"\n",
    "    Embedding class.\n",
    "    Examples::\n",
    "        >>> import matchzoo as mz\n",
    "        >>> train_raw = mz.datasets.toy.load_data()\n",
    "        >>> pp = mz.preprocessors.NaivePreprocessor()\n",
    "        >>> train = pp.fit_transform(train_raw, verbose=0)\n",
    "        >>> vocab_unit = mz.build_vocab_unit(train, verbose=0)\n",
    "        >>> term_index = vocab_unit.state['term_index']\n",
    "        >>> embed_path = mz.datasets.embeddings.EMBED_RANK\n",
    "    To load from a file:\n",
    "        >>> embedding = mz.embedding.load_from_file(embed_path)\n",
    "        >>> matrix = embedding.build_matrix(term_index)\n",
    "        >>> matrix.shape[0] == len(term_index) + 1\n",
    "        True\n",
    "    To build your own:\n",
    "        >>> data = pd.DataFrame(data=[[0, 1], [2, 3]], index=['A', 'B'])\n",
    "        >>> embedding = mz.Embedding(data)\n",
    "        >>> matrix = embedding.build_matrix({'A': 2, 'B': 1})\n",
    "        >>> matrix.shape == (3, 2)\n",
    "        True\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Embedding.\n",
    "        :param data: DataFrame to use as term to vector mapping.\n",
    "        \"\"\"\n",
    "        self._data = data\n",
    "\n",
    "    @property\n",
    "    def input_dim(self) -> int:\n",
    "        \"\"\":return Embedding input dimension.\"\"\"\n",
    "        return self._data.shape[0]\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        \"\"\":return Embedding output dimension.\"\"\"\n",
    "        return self._data.shape[1]\n",
    "\n",
    "    def build_matrix(\n",
    "        self,\n",
    "        term_index: typing.Union[\n",
    "            dict, mz.preprocessors.units.Vocabulary.TermIndex],\n",
    "        initializer=lambda: np.random.uniform(-0.2, 0.2)\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Build a matrix using `term_index`.\n",
    "        :param term_index: A `dict` or `TermIndex` to build with.\n",
    "        :param initializer: A callable that returns a default value for missing\n",
    "            terms in data. (default: a random uniform distribution in range)\n",
    "            `(-0.2, 0.2)`).\n",
    "        :return: A matrix.\n",
    "        \"\"\"\n",
    "        input_dim = len(term_index) + 1\n",
    "        \n",
    "        print('Embedding to matrix, input & output', input_dim, self.output_dim)\n",
    "        \n",
    "        matrix = np.empty((input_dim, self.output_dim))\n",
    "        for index in np.ndindex(*matrix.shape):\n",
    "            matrix[index] = initializer()\n",
    "\n",
    "        #valid_keys = set(self._data.index)\n",
    "        terms_to_find = term_index.keys()\n",
    "        valid_data_frame = self._data[self._data.index[-len(self._data):].isin(terms_to_find)]\n",
    "        \n",
    "        nf_count = 0\n",
    "        total = 0\n",
    "        \n",
    "        for term, values in valid_data_frame.iterrows():\n",
    "            if total % 50000==0:\n",
    "                print('Words completed', total)\n",
    "            total +=1\n",
    "                \n",
    "            try:\n",
    "                matrix[term_index[term]] = values\n",
    "            except Exception as ex:\n",
    "                nf_count+=1\n",
    "                print('Word not found', term)\n",
    "                    \n",
    "        print('Words not found in embedding ', nf_count)\n",
    "        \n",
    "        return matrix\n",
    "\n",
    "\n",
    "def load_from_file(file_path: str, mode: str = 'word2vec') -> Embedding:\n",
    "    \"\"\"\n",
    "    Load embedding from `file_path`.\n",
    "    :param file_path: Path to file.\n",
    "    :param mode: Embedding file format mode, one of 'word2vec' or 'glove'.\n",
    "        (default: 'word2vec')\n",
    "    :return: An :class:`matchzoo.embedding.Embedding` instance.\n",
    "    \"\"\"\n",
    "    if mode == 'word2vec':\n",
    "        data = pd.read_csv(file_path,\n",
    "                           sep=\" \",\n",
    "                           index_col=0,\n",
    "                           header=None,\n",
    "                           skiprows=1)\n",
    "        print(data.head())\n",
    "    elif mode == 'glove':\n",
    "        data = pd.read_csv(file_path,\n",
    "                           sep=\" \",\n",
    "                           index_col=0,\n",
    "                           header=None,\n",
    "                           quoting=csv.QUOTE_NONE)\n",
    "    else:\n",
    "        raise TypeError(f\"{mode} is not a supported embedding type.\"\n",
    "                        f\"`word2vec` or `glove` expected.\")\n",
    "    return Embedding(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "slist = ast.literal_eval(open('msmarco_data/long_stop_words','r').read())\n",
    "\n",
    "stop_words = list( set(['are', 'get','you','dont','want','take','have','need','let','your','their','theirs',\\\n",
    "              'still','these','that','could','should', 'would', 'with','does','this','used','make',\\\n",
    "              'makes','made','takes','take','those','when','without','more','becasue','there','aren',\\\n",
    "              'keep','seem','seems','wont','shouldn','shouldnt','only','than','know','every','also',\\\n",
    "              'brand','become','most','other','others','meant','thing','things','happens','anything',\\\n",
    "              'gets','sets','both','bring','then','goes','some','someone','see','article','redirect',\\\n",
    "              'sent','into','about','what','where','give','going','like','look','looks','having','other',\\\n",
    "              'gives','give','given','uses','used','through','though','very','doesn','many','even','mine',\\\n",
    "              'myself','always', 'self','currently','along','else','comes','come','came','likes','like',\\\n",
    "              'because','can','the', 'an', 'to', 'and', 'from', 'for', 'we', 'you', 'i', 'so','such',\\\n",
    "               'a', 'at', 'b', 'be', 'in', 'of', 'on', 'was', 'is','been','while','will','they','them']) | \\\n",
    "                set(slist))\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! tar -xvzf msmarco_data/collectionandqueries.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/manishav/irexplain/src/main/python/deep_explain/msmarco_data/'\n",
    "collection_path = path+ 'collection/'\n",
    "embedding_path =  path+ 'embedding/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "query_list = []\n",
    "match_words = r'define|what|when'\n",
    "\n",
    "for line in open(collection_path+'queries.train.tsv','r'):\n",
    "    split = line.strip().split('\\t')\n",
    "    \n",
    "    match = re.search(match_words,split[1])\n",
    "    if not match:\n",
    "        query_list.append({'qid':split[0], 'query': split[1].strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_frame = pd.DataFrame(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510633</td>\n",
       "      <td>tattoo fixers how much does it cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278900</td>\n",
       "      <td>how many cars enter the la jolla concours d' e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303205</td>\n",
       "      <td>how much can i contribute to nondeductible ira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>492875</td>\n",
       "      <td>sanitizer temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54528</td>\n",
       "      <td>blood clots in urine after menopause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid                                              query\n",
       "0  510633                tattoo fixers how much does it cost\n",
       "1  278900  how many cars enter the la jolla concours d' e...\n",
       "2  303205     how much can i contribute to nondeductible ira\n",
       "3  492875                              sanitizer temperature\n",
       "4   54528               blood clots in urine after menopause"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478643, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = []\n",
    "for line in open(collection_path+'qrels.train.tsv','r'):\n",
    "    split = line.strip().split('\\t')\n",
    "    qrels.append({'qid':split[0], 'pid': split[2], 'rel':split[3] })\n",
    "qrel_frame = pd.DataFrame(qrels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1185868</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597651</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403613</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183785</td>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid  pid rel\n",
       "0  1185869    0   1\n",
       "1  1185868   16   1\n",
       "2   597651   49   1\n",
       "3   403613   60   1\n",
       "4  1183785  389   1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502939"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame['qid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516472"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame['pid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532761, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://msmarco.blob.core.windows.net/msmarcoranking/qidpidtriples.train.full.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the negative triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 258\n",
      "2000000 267\n",
      "3000000 268\n",
      "4000000 268\n",
      "5000000 268\n",
      "6000000 268\n",
      "6000000 268\n",
      "6000000 268\n",
      "6000000 268\n",
      "6000000 268\n"
     ]
    }
   ],
   "source": [
    "neg_rows = []\n",
    "query_count = {}\n",
    "count = 0\n",
    "total_queries = 0\n",
    "\n",
    "test_query ={ }\n",
    "\n",
    "for line in open('qidpidtriples.train.full.tar','r'):\n",
    "    split = line.split('\\t')\n",
    "    qid = split[0]\n",
    "    \n",
    "    if qid not in query_count:\n",
    "        query_count[qid] = 0\n",
    "        total_queries+=1\n",
    "        if random.random() > 0.999:\n",
    "            test_query[qid] = 0\n",
    "        \n",
    "        # add the query to test with some prob\n",
    "    \n",
    "    if qid not in test_query and query_count[qid]< 20:\n",
    "        neg_rows.append({'qid': qid, 'pid':  split[2].strip(), 'rel':0})\n",
    "        query_count[qid]+=1\n",
    "        count+=1 \n",
    "        \n",
    "    elif qid in test_query and query_count[qid] < 1000:\n",
    "        neg_rows.append({'qid': qid, 'pid':  split[2].strip(), 'rel':0})\n",
    "        query_count[qid]+=1\n",
    "        test_query[qid] +=1\n",
    "        count+=1\n",
    "        \n",
    "    if count % 5000000 == 0:\n",
    "        print(count, len(test_query))\n",
    "        \n",
    "    #if count > 10000000:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327721"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_frame = pd.DataFrame(neg_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1185868</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403613</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>645590</td>\n",
       "      <td>944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>186154</td>\n",
       "      <td>1160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid   pid rel\n",
       "0  1185869     0   1\n",
       "1  1185868    16   1\n",
       "3   403613    60   1\n",
       "7   645590   944   1\n",
       "9   186154  1160   1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame = pd.concat([qrel_frame[qrel_frame['qid'].isin(neg_frame['qid'].unique().tolist())], neg_frame])\n",
    "qrel_frame.drop_duplicates(inplace=True)\n",
    "qrel_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6723391</th>\n",
       "      <td>908904</td>\n",
       "      <td>8610436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723392</th>\n",
       "      <td>296496</td>\n",
       "      <td>713532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723393</th>\n",
       "      <td>774829</td>\n",
       "      <td>7112242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723394</th>\n",
       "      <td>840632</td>\n",
       "      <td>7024083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723395</th>\n",
       "      <td>558656</td>\n",
       "      <td>7798884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            qid      pid rel\n",
       "6723391  908904  8610436   0\n",
       "6723392  296496   713532   0\n",
       "6723393  774829  7112242   0\n",
       "6723394  840632  7024083   0\n",
       "6723395  558656  7798884   0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7059101, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_pid_rel_frame = pd.merge(query_frame, qrel_frame, left_on='qid', right_on='qid', suffixes=('', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3971101, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid_pid_rel_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3775066\n",
       "1     196035\n",
       "Name: rel, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid_pid_rel_frame['rel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_pid_rel_frame['rel'] = qid_pid_rel_frame['rel'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3971101, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_frame[qrel_frame['qid'].isin(query_frame['qid'].tolist())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_set = set(qid_pid_rel_frame['pid'].tolist())\n",
    "\n",
    "paragraphs = []\n",
    "for line in open(collection_path+'collection.tsv','r'):\n",
    "    split = line.strip().split('\\t')\n",
    "    if split[0] in pid_set:\n",
    "        paragraphs.append({'pid': split[0],\\\n",
    "                           'paragraph': split[1].strip()})\n",
    "        \n",
    "para_frame = pd.DataFrame(paragraphs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1638556, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_pid_para_rel_frame = pd.merge(qid_pid_rel_frame, para_frame, left_on='pid', right_on='pid', suffixes=('', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>pid</th>\n",
       "      <th>rel</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303205</td>\n",
       "      <td>how much can i contribute to nondeductible ira</td>\n",
       "      <td>6487240</td>\n",
       "      <td>1</td>\n",
       "      <td>Nondeductible IRA Contributions. For a traditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303205</td>\n",
       "      <td>how much can i contribute to nondeductible ira</td>\n",
       "      <td>821461</td>\n",
       "      <td>0</td>\n",
       "      <td>Just because you can contribute to a 401(k) pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11658</td>\n",
       "      <td>adjusted gross income  definition</td>\n",
       "      <td>821461</td>\n",
       "      <td>0</td>\n",
       "      <td>Just because you can contribute to a 401(k) pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68667</td>\n",
       "      <td>can i contribute to a roth ira without earned ...</td>\n",
       "      <td>821461</td>\n",
       "      <td>0</td>\n",
       "      <td>Just because you can contribute to a 401(k) pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>398833</td>\n",
       "      <td>irs pre-tax traditional ira contribution limits</td>\n",
       "      <td>821461</td>\n",
       "      <td>0</td>\n",
       "      <td>Just because you can contribute to a 401(k) pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid                                              query      pid  rel  \\\n",
       "0  303205     how much can i contribute to nondeductible ira  6487240    1   \n",
       "1  303205     how much can i contribute to nondeductible ira   821461    0   \n",
       "2   11658                  adjusted gross income  definition   821461    0   \n",
       "3   68667  can i contribute to a roth ira without earned ...   821461    0   \n",
       "4  398833    irs pre-tax traditional ira contribution limits   821461    0   \n",
       "\n",
       "                                           paragraph  \n",
       "0  Nondeductible IRA Contributions. For a traditi...  \n",
       "1  Just because you can contribute to a 401(k) pl...  \n",
       "2  Just because you can contribute to a 401(k) pl...  \n",
       "3  Just because you can contribute to a 401(k) pl...  \n",
       "4  Just because you can contribute to a 401(k) pl...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid_pid_para_rel_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(para_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishav/addons/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid_pid_para_rel_frame[qid_pid_para_rel_frame['rel'] == '1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare train and test_frame for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import random \n",
    "# sample 10K queries\n",
    "query_list = qid_pid_para_rel_frame['qid'].drop_duplicates().tolist()\n",
    "print(len(query_list))\n",
    "test_queries = list(test_query.keys())\n",
    "train_queries = random.sample(list(set(query_list) - set(test_queries)), 50000)\n",
    "\n",
    "final_train_frame = shuffle(qid_pid_para_rel_frame[qid_pid_para_rel_frame['qid'].isin(train_queries)][['query','paragraph','rel']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_frame = final_train_frame.reset_index(drop=True)\n",
    "final_train_frame.columns=['text_left','text_right','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_left</th>\n",
       "      <th>text_right</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many calories are burned walking 10 000 steps</td>\n",
       "      <td>Calories, Fat, Protein, Fiber, &amp; Carbs In Pane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how are northern lights formed chemistry expla...</td>\n",
       "      <td>Fort McMurray can be found on the 56th paralle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>illinois state revenue tax</td>\n",
       "      <td>Minnesota State Tax Information. Looking for M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>most likely awards for students</td>\n",
       "      <td>Iggy Azalea Wins Top Rap Artist At The Billboa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you use wax paper instead of parchment</td>\n",
       "      <td>Wash Wax ALL has also been found to be excelle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_left  \\\n",
       "0  how many calories are burned walking 10 000 steps   \n",
       "1  how are northern lights formed chemistry expla...   \n",
       "2                         illinois state revenue tax   \n",
       "3                    most likely awards for students   \n",
       "4         can you use wax paper instead of parchment   \n",
       "\n",
       "                                          text_right  label  \n",
       "0  Calories, Fat, Protein, Fiber, & Carbs In Pane...      0  \n",
       "1  Fort McMurray can be found on the 56th paralle...      0  \n",
       "2  Minnesota State Tax Information. Looking for M...      0  \n",
       "3  Iggy Azalea Wins Top Rap Artist At The Billboa...      0  \n",
       "4  Wash Wax ALL has also been found to be excelle...      0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sample queries for test (should not overlap with train)\n",
    "final_test_frame = shuffle(qid_pid_para_rel_frame[qid_pid_para_rel_frame['qid'].isin(test_queries)]\\\n",
    "                            [['query','paragraph','rel']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_left</th>\n",
       "      <th>text_right</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who dna is the transforming principle from hea...</td>\n",
       "      <td>Norovirus was once known as Norwalk virus and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who is tim lincecum playing for in 2016</td>\n",
       "      <td>The lineup consisted of Jim (Joe Buck) on voca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nc propane cost</td>\n",
       "      <td>Propane-Prices.com was created to help all hom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can i use global entry card for tsa precheck</td>\n",
       "      <td>Applicants will log into the account and pay t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how long does chicken last after thawed</td>\n",
       "      <td>Directions. 1  Place a Cast Iron Frying Pan in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_left  \\\n",
       "0  who dna is the transforming principle from hea...   \n",
       "1            who is tim lincecum playing for in 2016   \n",
       "2                                    nc propane cost   \n",
       "3       can i use global entry card for tsa precheck   \n",
       "4            how long does chicken last after thawed   \n",
       "\n",
       "                                          text_right  label  \n",
       "0  Norovirus was once known as Norwalk virus and ...      0  \n",
       "1  The lineup consisted of Jim (Joe Buck) on voca...      0  \n",
       "2  Propane-Prices.com was created to help all hom...      0  \n",
       "3  Applicants will log into the account and pay t...      0  \n",
       "4  Directions. 1  Place a Cast Iron Frying Pan in...      0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_frame = final_test_frame.reset_index(drop=True)\n",
    "final_test_frame.columns=['text_left','text_right','label']\n",
    "final_test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw =  mz.pack(final_train_frame)# mz.datasets.toy.load_data(stage='train', task=task)\n",
    "test_raw =  mz.pack(final_test_frame)#mz.datasets.toy.load_data(stage='test', task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_left</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L-0</th>\n",
       "      <td>how many calories are burned walking 10 000 steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-1</th>\n",
       "      <td>how are northern lights formed chemistry expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-2</th>\n",
       "      <td>illinois state revenue tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-3</th>\n",
       "      <td>most likely awards for students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-4</th>\n",
       "      <td>can you use wax paper instead of parchment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text_left\n",
       "id_left                                                   \n",
       "L-0      how many calories are burned walking 10 000 steps\n",
       "L-1      how are northern lights formed chemistry expla...\n",
       "L-2                             illinois state revenue tax\n",
       "L-3                        most likely awards for students\n",
       "L-4             can you use wax paper instead of parchment"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.left.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = mz.preprocessors.BasicPreprocessor(fixed_length_left=15,\n",
    "             fixed_length_right=30,\n",
    "             filter_mode='idf',\n",
    "             filter_low_freq=2,\n",
    "             filter_low_freq=2,\n",
    "             remove_stop_words=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 50000/50000 [00:16<00:00, 3102.60it/s]\n",
      "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 703665/703665 [18:08<00:00, 646.50it/s]  \n",
      "Processing text_right with append: 100%|██████████| 703665/703665 [00:01<00:00, 448330.59it/s]\n",
      "Building FrequencyFilter from a datapack.: 100%|██████████| 703665/703665 [00:18<00:00, 38972.38it/s]\n",
      "Processing text_right with transform: 100%|██████████| 703665/703665 [00:23<00:00, 29635.34it/s]\n",
      "Processing text_left with extend: 100%|██████████| 50000/50000 [00:00<00:00, 427762.36it/s]\n",
      "Processing text_right with extend: 100%|██████████| 703665/703665 [00:02<00:00, 328270.65it/s]\n",
      "Building Vocabulary from a datapack.: 100%|██████████| 24042325/24042325 [00:13<00:00, 1810828.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matchzoo.preprocessors.basic_preprocessor.BasicPreprocessor at 0x7fd1e94a5390>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582696"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessor.context['vocab_unit'].state['term_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = preprocessor.transform(train_raw,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed = preprocessor.transform(test_raw,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig Text: [529130, 546991, 329046, 219779, 207729, 100714, 49393, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Transformed Indices: [529130, 546991, 329046, 219779, 207729, 100714, 49393, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Transformed Indices Meaning: many_calories_burned_walking_10_000_steps_<PAD>_<PAD>_<PAD>_<PAD>_<PAD>_<PAD>_<PAD>_<PAD>\n"
     ]
    }
   ],
   "source": [
    "vocab_unit = preprocessor.context['vocab_unit']\n",
    "print('Orig Text:', train_processed.left.loc['L-0']['text_left'])\n",
    "sequence = train_processed.left.loc['L-0']['text_left']\n",
    "print('Transformed Indices:', sequence)\n",
    "print('Transformed Indices Meaning:',\n",
    "      '_'.join([vocab_unit.state['index_term'][i] for i in sequence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the ranking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Task\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task = mz.tasks.Ranking()\n",
    "task.metrics = [PrecisionCheck(k=3, threshold=0),\n",
    "    PrecisionCheck(k=5, threshold=0),\n",
    "    RecallCheck(k=3, threshold=0),\n",
    "    RecallCheck(k=5, threshold=0),\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=3, threshold=0),\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=5, threshold=0),\n",
    "]\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {embedding_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator = mz.PairDataGenerator(train_processed, num_dup=1, num_neg=4, batch_size=32, shuffle=True)\n",
    "#len(train_generator)\n",
    "word_embeddings = load_from_file(embedding_path+'glove.6B.50d.txt', mode= 'glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit_generator(train_generator, epochs=20, callbacks=[evaluate], workers=5, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model param model_class                   <class 'matchzoo.models.drmmtks.DRMMTKS'>\n",
      "input_shapes                  [(15,), (30,)]\n",
      "task                          Ranking Task\n",
      "optimizer                     adadelta\n",
      "with_embedding                True\n",
      "embedding_input_dim           582696\n",
      "embedding_output_dim          50\n",
      "embedding_trainable           True\n",
      "with_multi_layer_perceptron   True\n",
      "mlp_num_units                 20\n",
      "mlp_num_layers                2\n",
      "mlp_num_fan_out               10\n",
      "mlp_activation_func           tanh\n",
      "mask_value                    -1\n",
      "top_k                         10\n",
      "Model complete True\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_left (InputLayer)          (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_right (InputLayer)         (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             29134800    text_left[0][0]                  \n",
      "                                                                 text_right[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 15, 30)       0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 15, 10)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 15, 1)        50          embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 15, 20)       220         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (Lambda)         (None, 15, 1)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 15, 20)       420         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_probs (Lambda)        (None, 15, 1)        0           attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 15, 10)       210         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1, 10)        0           attention_probs[0][0]            \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            11          flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,135,711\n",
      "Trainable params: 29,135,711\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = mz.models.DRMMTKS()\n",
    "model.params['task'] = task\n",
    "model.params['embedding_input_dim'] =  len(preprocessor.context['vocab_unit'].state['term_index']) +1 \n",
    "model.params['embedding_output_dim'] = word_embeddings.output_dim\n",
    "#model.params['embedding_output_dim'] = 11\n",
    "\n",
    "model.params['top_k'] = 10\n",
    "model.params['mlp_num_layers'] = 2\n",
    "model.params['mlp_num_units'] = 20\n",
    "model.params['mlp_num_fan_out'] = 10\n",
    "model.params['mlp_activation_func'] = 'tanh'\n",
    "model.params['optimizer'] = 'adadelta'\n",
    "#model.params['mlp_num_units'] = mlp_units\n",
    "\n",
    "model.params['embedding_trainable'] = True\n",
    "\n",
    "model.guess_and_fill_missing_params(verbose=1)\n",
    "\n",
    "model.params.update(preprocessor.context)\n",
    "print('Model param',model.params)\n",
    "\n",
    "model.build()\n",
    "#model.load_embedding_matrix(embedding_matrix)\n",
    "model.compile()\n",
    "print('Model complete',model.params.completed())\n",
    "model.backend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = mz.DataGenerator(\n",
    "                train_processed, mode='pair',num_dup=1, num_neg=10,batch_size=100\n",
    ")\n",
    "print('training data batches:', len(train_generator))\n",
    "history = model.fit_generator(train_generator, epochs=5, \\\n",
    "                                  workers=4, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_processed.unpack()\n",
    "test_x, test_y = test_processed.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "587752/587752 [==============================] - 441s 750us/step - loss: 0.0758\n",
      "Epoch 2/2\n",
      "587752/587752 [==============================] - 474s 807us/step - loss: 0.0744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd0a610be80>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=1000, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    pred_x, pred_y = test_processed[:].unpack()\n",
    "    evaluate = mz.callbacks.EvaluateAllMetrics(model, x=pred_x, y=pred_y, batch_size=len(pred_x))\n",
    "    ?evaluate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_left': array(['L-0', 'L-1', 'L-2', ..., 'L-117', 'L-31', 'L-87'], dtype='<U5'),\n",
       " 'text_left': array([[299379, 490362, 294996, ...,      0,      0,      0],\n",
       "        [ 27720, 309675, 203865, ...,      0,      0,      0],\n",
       "        [105424, 170437, 320625, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [550372, 490816, 478216, ...,      0,      0,      0],\n",
       "        [346282, 367283, 451831, ...,      0,      0,      0],\n",
       "        [393456, 511072,  80487, ...,      0,      0,      0]]),\n",
       " 'length_left': array([11,  4,  3, ...,  4,  7,  4]),\n",
       " 'id_right': array(['R-0', 'R-1', 'R-2', ..., 'R-121631', 'R-121632', 'R-121633'],\n",
       "       dtype='<U8'),\n",
       " 'text_right': array([[ 99882, 408547, 242273, ...,      0,      0,      0],\n",
       "        [ 90299, 495356, 148956, ...,  75093,      0,      0],\n",
       "        [464449, 391651,  82043, ..., 170437, 280762,  96984],\n",
       "        ...,\n",
       "        [319298, 188291, 524349, ..., 498453, 177608,      0],\n",
       "        [ 88915, 261839, 562739, ..., 132953, 467108,  89296],\n",
       "        [546787, 325759, 511072, ...,      0,      0,      0]]),\n",
       " 'length_right': array([27, 28, 30, ..., 29, 30, 26])}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127632, 30)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x['text_right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127632, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test_predict = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[299379,\n",
       " 490362,\n",
       " 294996,\n",
       " 167647,\n",
       " 514817,\n",
       " 436877,\n",
       " 146667,\n",
       " 181003,\n",
       " 390819,\n",
       " 514817,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed.left.loc['L-0']['text_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with_topK(model, test_x, test_predict, test_processed, \\\n",
    "                        preprocessor, topk, doc_score_file, word_score_file):\n",
    "    \n",
    "    \n",
    "    qid_did_score = {}\n",
    "    vocab_unit = preprocessor.context['vocab_unit']\n",
    "    for left_id, right_id, score in zip(test_x['id_left'], test_x['id_right'], test_predict):\n",
    "        if left_id not in qid_did_score:\n",
    "            qid_did_score[left_id] = {}\n",
    "        qid_did_score[left_id][right_id] = score\n",
    "    \n",
    "    # get top 100\n",
    "    doc_score_rows = []\n",
    "    word_score_rows = []\n",
    "    \n",
    "    query_text_mapping = {}\n",
    "    doc_text_mapping = {}\n",
    "    \n",
    "    for qid, dscore in qid_did_score.items():\n",
    "        top_docs = sorted(dscore.items(), key = lambda x: x[1], reverse=True)\n",
    "        qtext = ' '.join([vocab_unit.state['index_term'][i] for i in \\\n",
    "                          test_processed.left.loc[qid]['text_left']])\n",
    "        query_text_mapping[qid] = qtext\n",
    "        covered_tokens = {}\n",
    "        for sentry in top_docs[:100]:\n",
    "            doc_token_id = test_processed.right.loc[sentry[0]]['text_right']\n",
    "            dtext = ' '.join([vocab_unit.state['index_term'][i] for i in doc_token_id])\n",
    "            doc_text_mapping[sentry[0]] = dtext\n",
    "            wid_left=[]\n",
    "            wid_right=[]\n",
    "            wtext_left=[]\n",
    "            wtext_right=[]\n",
    "            \n",
    "            tid = 0\n",
    "            right_len = len(doc_token_id)\n",
    "            for token_id in doc_token_id:\n",
    "                if token_id not in covered_tokens:\n",
    "                    wid_left.append(qid)\n",
    "                    wtext_left.append(test_processed.left.loc[qid]['text_left'])\n",
    "                    wid_right.append('R-'+str(tid))\n",
    "                    right_vector = np.zeros(right_len)\n",
    "                    right_vector[0] = token_id\n",
    "                    wtext_right.append(right_vector)\n",
    "                    tid+=1\n",
    "                    covered_tokens[token_id] = 0.0\n",
    "                covered_tokens[token_id] += 1.0\n",
    "            \n",
    "            if len(wtext_right) > 0:\n",
    "                word_test_object = {}\n",
    "                word_test_object['text_left'] = np.array(wtext_left)\n",
    "                word_test_object['text_right'] = np.array(wtext_right)\n",
    "                #word_test_object['id_left'] = np.array(word_test_object['id_left'])\n",
    "                #word_test_object['id_right'] = np.array(word_test_object['id_right'])\n",
    "                \n",
    "                wpred_scores = model.predict(word_test_object)\n",
    "                for token_vector, score in zip(word_test_object['text_right'], wpred_scores):\n",
    "                    word = vocab_unit.state['index_term'][token_vector[0]]\n",
    "                    \n",
    "                    if word!='<PAD>':\n",
    "                        word_score_rows.append({'qid': qid, 'pid': sentry[0], 'word': word,\\\n",
    "                                            'wscore': score[0]})\n",
    "            \n",
    "            doc_score_rows.append({'qid': qid, 'pid': sentry[0], 'score': sentry[1][0]})\n",
    "            \n",
    "    pd.DataFrame(doc_score_rows).to_csv(doc_score_file,header=True, sep='\\t', index=False)\n",
    "    pd.DataFrame(word_score_rows).to_csv(word_score_file,header=True, sep='\\t', index=False)\n",
    "    del(doc_score_rows)\n",
    "    \n",
    "    \n",
    "        \n",
    "    qfile = open('query_id_mapping.csv','w')\n",
    "    for qid, qtext in query_text_mapping.items():\n",
    "        qfile.write(qid+'\\t'+qtext+'\\n')\n",
    "    qfile.close()\n",
    "    \n",
    "    dfile = open('doc_id_mapping.csv','w')\n",
    "    for did, dtext in doc_text_mapping.items():\n",
    "        dfile.write(did+'\\t'+dtext+'\\n')\n",
    "    dfile.close()\n",
    "    \n",
    "\n",
    "    # qid, query text, doc id , doc score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_model_with_topK(model, test_x, test_predict, test_processed, preprocessor, \\\n",
    "                    100, 'drmm_doc_scores_top100.csv','drmm_word_scores_top100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove the queries from test that have less than X documents. \n",
    "* MRR\n",
    "* Add attention to the first layer. (use the queries to explain)\n",
    "* Check attention after histogram layer. (use the queries to explain)\n",
    "* unit of explanation: word/histogram "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
